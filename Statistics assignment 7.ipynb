{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b657f753-f66e-4b23-abcf-fa9fd6d8d9d2",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8c8c3-ebf3-4c46-b94f-5f68626c32d3",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means across multiple groups or treatments. It makes several assumptions about the data to ensure the validity of the results. Violations of these assumptions can lead to incorrect conclusions and compromised validity of ANOVA results. The main assumptions of ANOVA are:\n",
    "\n",
    "1.Independence: The observations within each group are assumed to be independent of each other. This means that the values in one group do not affect or influence the values in another group.\n",
    "\n",
    "2.Normality: The data within each group should follow a normal distribution. Normality assumption is more crucial when sample sizes are small, as ANOVA is known to be quite robust to deviations from normality when sample sizes are large.\n",
    "\n",
    "3.Homogeneity of Variance (Homoscedasticity): The variances of the data in each group should be roughly equal. This assumption is important because ANOVA assumes that the variability within each group is comparable across all groups.\n",
    "\n",
    "4.Random Sampling: The samples are assumed to be drawn randomly from their respective populations. This assumption ensures that the sample data is representative of the larger population.\n",
    "\n",
    "Now, let's discuss examples of violations for each assumption:\n",
    "\n",
    "1.Independence:\n",
    "\n",
    "Example Violation: In a study examining the effects of exercise on weight loss, if participants in the same household are included in different exercise groups, their weight loss measurements might be correlated due to shared factors like diet and lifestyle.\n",
    "\n",
    "2.Normality:\n",
    "\n",
    "Example Violation: In a comparison of exam scores among students from different schools, if the scores within each school are not normally distributed but skewed, the normality assumption might be violated.\n",
    "\n",
    "3.Homogeneity of Variance:\n",
    "\n",
    "Example Violation: Consider a study comparing the performance of two different teaching methods across schools. If the variance of test scores in one teaching method is much larger than the variance in the other, the assumption of equal variances might be violated.\n",
    "\n",
    "4.Random Sampling:\n",
    "\n",
    "Example Violation: In a study investigating the effects of a new drug, if participants are not randomly assigned to treatment and control groups, the assumption of random sampling might be violated, leading to biased results.\n",
    "\n",
    "When these assumptions are violated, the validity of ANOVA results can be compromised. If the data doesn't meet the assumptions, researchers might need to consider alternative analyses or transformations of the data to mitigate the impact of these violations. Additionally, there are non-parametric alternatives to ANOVA, like the Kruskal-Wallis test, which are less sensitive to assumptions of normality and homogeneity of variance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4256b8a0-7d05-467f-9434-36148c1c9b15",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7076ab3-7908-48ea-94d3-ce291e21b2ab",
   "metadata": {},
   "source": [
    "There are three main types of Analysis of Variance (ANOVA), each designed to handle specific types of experimental designs and research questions:\n",
    "\n",
    "1.One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when there is a single categorical independent variable (factor) with three or more levels (groups), and the goal is to determine whether there are any statistically significant differences in the means of the dependent variable across these groups.\n",
    "\n",
    "Example: A pharmaceutical company wants to compare the effectiveness of three different doses of a new drug in reducing blood pressure. The independent variable is the drug dose (low, medium, high), and the dependent variable is the reduction in blood pressure.\n",
    "\n",
    "2.Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when there are two categorical independent variables (factors) and the goal is to analyze the interaction effects between these factors on a continuous dependent variable.\n",
    "\n",
    "Example: An educational researcher wants to study the effects of teaching method (online vs. in-person) and student gender (male vs. female) on exam scores. This involves two independent variables, teaching method and gender, and their interaction effect.\n",
    "\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Repeated Measures ANOVA, also known as within-subjects ANOVA, is used when the same subjects are measured multiple times under different conditions. It's used to analyze how these repeated measurements change across different conditions.\n",
    "\n",
    "Example: A psychologist wants to investigate the effectiveness of three different therapies for treating anxiety. Each participant undergoes all three therapies (within-subjects factor) and their anxiety levels are measured after each session.\n",
    "\n",
    "These different types of ANOVA are chosen based on the research design and the nature of the independent variables. It's important to select the appropriate type of ANOVA that matches the experimental design and research question to ensure accurate and meaningful results. Additionally, there are variations and extensions of ANOVA, such as mixed-design ANOVA, which combine elements of different ANOVA types to handle more complex experimental designs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d08ee25-2c46-46ff-b551-856bfad8c913",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdf820-9d9b-49cf-944f-64bb2da39d13",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variability observed in the data into different components that are attributed to specific sources of variation. This decomposition helps in understanding how much of the total variance can be explained by the factors being studied and how much is due to random variability or unexplained error. The partitioning of variance is a fundamental concept in ANOVA and is essential for interpreting the results and drawing meaningful conclusions from the analysis.\n",
    "\n",
    "In ANOVA, the total variance of the dependent variable is divided into three main components:\n",
    "\n",
    "1.Between-Group Variance (Treatment Variance): This component of variance measures the differences between the group means. It reflects the variability that can be attributed to the effects of the independent variable(s) or treatment(s). If the between-group variance is large compared to the within-group variance, it suggests that the treatments have a significant effect on the dependent variable.\n",
    "\n",
    "2.Within-Group Variance (Error Variance): This component of variance accounts for the variability within each group or treatment. It represents the random variability that cannot be explained by the factors under study. It includes individual differences, measurement error, and other unaccounted sources of variation.\n",
    "\n",
    "3.Total Variance: This is the overall variability observed in the data and is the sum of the between-group variance and the within-group variance. It provides a baseline against which the contributions of the other components are evaluated.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1.Interpretation of Significance: By comparing the magnitudes of the between-group and within-group variances, you can determine whether the differences between groups are statistically significant. This is essential for making valid conclusions about the effects of the independent variables.\n",
    "\n",
    "2.Effect Size: The proportion of total variance explained by the between-group variance, known as the effect size, indicates the practical significance of the findings. A larger effect size suggests a stronger influence of the independent variables.\n",
    "\n",
    "3.Model Assessment: Partitioning of variance helps assess the goodness of fit of the ANOVA model. If the explained variance (between-group) is much larger than the unexplained variance (within-group), it suggests that the model fits the data well.\n",
    "\n",
    "4.Identifying Sources of Variation: By identifying how much variance is attributable to different sources, researchers gain insights into which factors are driving the observed differences and how much variability is due to random chance.\n",
    "\n",
    "Overall, understanding the partitioning of variance in ANOVA is crucial for accurately interpreting the results, determining the significance of effects, and making informed decisions based on the data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e422720-0913-4103-b414-68ca3f7278cd",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7aa462-1117-40dc-8e0a-95abb9cd921e",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the total sum of squares (SST) represents the total variability in the data, the explained sum of squares (SSE) represents the variability explained by the group means, and the residual sum of squares (SSR) represents the unexplained variability within each group. You can calculate these values using Python and libraries like NumPy or scipy.stats. Here's how you would do it:\n",
    "\n",
    "Assuming you have a dataset with multiple groups, and the data for each group is stored in separate arrays or lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5a8b35-4698-453b-9695-3ecdb9281860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 955.3333333333333\n",
      "Explained Sum of Squares (SSE): 845.7333333333337\n",
      "Residual Sum of Squares (SSR): 109.59999999999957\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for each group\n",
    "group1 = [23, 28, 32, 26, 30]\n",
    "group2 = [18, 21, 25, 19, 22]\n",
    "group3 = [35, 40, 42, 38, 41]\n",
    "\n",
    "# Combine all data into one array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate total sum of squares (SST)\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate explained sum of squares (SSE)\n",
    "sse = len(group1) * (group1_mean - overall_mean)**2 + \\\n",
    "      len(group2) * (group2_mean - overall_mean)**2 + \\\n",
    "      len(group3) * (group3_mean - overall_mean)**2\n",
    "\n",
    "# Calculate residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972bda6c-b373-4b04-aaf5-7cd1bd5310c8",
   "metadata": {},
   "source": [
    "In this example, group1, group2, and group3 represent the data for each group. The total sum of squares (SST) is calculated by summing the squared differences between each data point and the overall mean. The explained sum of squares (SSE) is calculated as the sum of squared differences between each group mean and the overall mean, multiplied by the number of observations in each group. The residual sum of squares (SSR) is the difference between SST and SSE.\n",
    "\n",
    "Note that in practice, you can utilize libraries like scipy.stats.f_oneway to perform ANOVA directly and obtain these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628341a4-4418-40bc-abcb-83b891504c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 46.29927007299274\n",
      "P-value: 2.279994171783364e-06\n"
     ]
    }
   ],
   "source": [
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2e45e-d100-44b4-96a6-e3464b7a2dd0",
   "metadata": {},
   "source": [
    "The F-statistic is related to the ratio of the explained variability to the unexplained variability, and the p-value helps you determine whether the group means are significantly different."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b6928d6-6003-40d5-b18e-b988cd9794c4",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74d109-737c-4c08-b6bd-e6380127f587",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, you can calculate the main effects and interaction effects to analyze how two categorical independent variables (factors) influence a continuous dependent variable. You can use Python and libraries like NumPy and SciPy to perform these calculations. Here's how you would calculate the main effects and interaction effects:\n",
    "\n",
    "Assuming you have your data organized in a structured format (e.g., a DataFrame) with two categorical factors and a continuous dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a206b49-d5d5-43c5-8dff-39fef1eec441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor1: 104.16666666666656\n",
      "Main Effect of Factor2: 16.666666666666686\n",
      "Interaction Effect: 4.1666666666666785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Factor1': ['A', 'A', 'B', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "    'DependentVar': [10, 15, 20, 25, 12, 18, 8, 22]\n",
    "})\n",
    "\n",
    "# Perform a two-way ANOVA using statsmodels\n",
    "formula = 'DependentVar ~ Factor1 + Factor2 + Factor1:Factor2'\n",
    "model = ols(formula, data).fit()\n",
    "table = anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effects from the ANOVA table\n",
    "main_effect_factor1 = table.loc['Factor1', 'sum_sq'] / table.loc['Factor1', 'df']\n",
    "main_effect_factor2 = table.loc['Factor2', 'sum_sq'] / table.loc['Factor2', 'df']\n",
    "interaction_effect = table.loc['Factor1:Factor2', 'sum_sq'] / table.loc['Factor1:Factor2', 'df']\n",
    "\n",
    "print(\"Main Effect of Factor1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebed15-93d6-4df6-b05a-9f07b1f939ce",
   "metadata": {},
   "source": [
    "In this example, Factor1 and Factor2 represent the two categorical independent variables, and DependentVar represents the continuous dependent variable. The two-way ANOVA is performed using the statsmodels library, and the ANOVA table is obtained using the anova_lm function.\n",
    "\n",
    "The main effects of Factor1 and Factor2 are calculated by dividing the sum of squares of the respective factors by their degrees of freedom. The interaction effect is calculated similarly. These effects give you insights into the influence of each factor and whether they interact with each other in affecting the dependent variable."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6c7bd0f-4748-42a1-8bf7-7b13ba45b6cb",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c012d-ebe7-4c52-83bf-925ad9201725",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of the groups are equal. A significant F-statistic indicates that there are significant differences between at least some of the group means. In your case, with an F-statistic of 5.23 and a p-value of 0.02, we can draw the following conclusions:\n",
    "\n",
    "1.Significant F-Statistic: The F-statistic of 5.23 indicates that there are differences between the group means. However, this value by itself does not tell us which groups are different from each other; it only suggests that at least one group mean is different from the rest.\n",
    "\n",
    "2.Small p-value: The p-value of 0.02 is less than the common significance level of 0.05. This indicates that the probability of obtaining such a large F-statistic under the assumption that all group means are equal (null hypothesis) is only 0.02. Since this p-value is below the significance level, we reject the null hypothesis.\n",
    "\n",
    "3.Conclusion: Based on the significant F-statistic and the small p-value, we can conclude that there are statistically significant differences between the groups. In other words, the data provides enough evidence to suggest that not all group means are equal.\n",
    "\n",
    "4.Post hoc Analysis: To determine which specific groups are different from each other, you would typically perform post hoc tests (e.g., Tukey's HSD, Bonferroni correction, etc.). These tests help identify the specific pairwise differences that are statistically significant.\n",
    "\n",
    "In summary, the F-statistic of 5.23 and the associated p-value of 0.02 suggest that there are significant differences between the groups in your study. However, to understand the nature of these differences and which specific groups are responsible for this significance, further post hoc analyses are necessary."
   ]
  },
  {
   "cell_type": "raw",
   "id": "65338dca-0d30-4e12-9f64-cec0b8a0663b",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1bc609-321f-4a40-9e63-b526314f9321",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is important to ensure accurate and reliable results. Repeated measures ANOVA involves analyzing data from the same subjects across multiple time points or conditions, making missing data more complex to deal with. Different methods can be used to handle missing data, each with its own potential consequences. Here are some common approaches and their potential consequences:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "Method: Exclude subjects with any missing data from the analysis.\n",
    "\n",
    "Consequences: This approach can lead to loss of valuable information and reduced statistical power. If missingness is related to the outcome or predictors, the analysis may become biased. Additionally, the remaining sample may no longer be representative of the initial sample.\n",
    "\n",
    "Mean Imputation:\n",
    "\n",
    "Method: Replace missing values with the mean of the observed values for that variable.\n",
    "\n",
    "Consequences: This approach can artificially reduce variability and may distort the relationships between variables. It also does not account for individual differences and may not be suitable for repeated measures data.\n",
    "\n",
    "Last Observation Carried Forward (LOCF) or Next Observation Carried Backward (NOCB):\n",
    "\n",
    "Method: Replace missing values with the last observed value for LOCF or the next observed value for NOCB.\n",
    "\n",
    "Consequences: This approach assumes that missing values remain constant over time, which may not be valid. It can distort temporal patterns and lead to biased estimates, especially if the missingness is not random.\n",
    "Interpolation or Linear Imputation:\n",
    "\n",
    "Method: Use interpolation or regression to estimate missing values based on the observed values around the missing data point.\n",
    "\n",
    "Consequences: While this approach can capture trends and patterns, it assumes linearity and might not be accurate if the underlying relationships are nonlinear or if there's substantial variability.\n",
    "\n",
    "Multiple Imputation:\n",
    "\n",
    "Method: Create multiple plausible imputations for missing values and analyze each imputed dataset separately before pooling results.\n",
    "\n",
    "Consequences: This approach accounts for uncertainty due to missing data and provides more accurate standard errors and p-values. However, it can be computationally intensive and requires careful implementation.\n",
    "\n",
    "The consequences of using different methods to handle missing data include potential bias, distorted relationships, inflated or deflated statistical significance, and inaccurate confidence intervals. The choice of method should consider the underlying nature of the data, the reasons for missingness, and the assumptions of each method. Researchers should aim for the most appropriate and transparent method, acknowledging the limitations and potential impact on the results and conclusions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c861c10-f5da-4f0d-8a86-878381fcd195",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57ed43-8736-4758-b80b-3f5287c84670",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after an Analysis of Variance (ANOVA) to make pairwise comparisons between group means when the ANOVA indicates a significant overall difference among groups. These tests help determine which specific groups are different from each other. Some common post-hoc tests include:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "Use Case: Tukey's HSD is appropriate when you want to control the familywise error rate across all possible pairwise comparisons. It's generally a good choice when you have a larger number of groups.\n",
    "\n",
    "Example: A researcher conducts a one-way ANOVA to compare the effectiveness of four different teaching methods on student performance. The ANOVA indicates a significant difference among the groups, and Tukey's HSD is used to determine which specific pairs of teaching methods differ significantly.\n",
    "\n",
    "Bonferroni Correction:\n",
    "\n",
    "Use Case: The Bonferroni correction is used when you need to control the familywise error rate while making multiple pairwise comparisons. It's a more conservative approach that's suitable when the number of comparisons is relatively small.\n",
    "\n",
    "Example: In a clinical trial, a three-way ANOVA is performed to assess the effects of different dosages of a drug, gender, and age group on patient outcomes. The ANOVA shows a significant effect, and the Bonferroni correction is used to compare the specific combinations of dosages, genders, and age groups.\n",
    "\n",
    "Dunn's Test:\n",
    "\n",
    "Use Case: Dunn's test is a non-parametric post-hoc test that is used when the data doesn't meet the assumptions of normality or equal variances. It's more appropriate for data that are not normally distributed.\n",
    "\n",
    "Example: A researcher analyzes the effects of various exercise routines on cardiovascular fitness using a Kruskal-Wallis test (non-parametric equivalent of ANOVA). The test shows a significant difference, and Dunn's test is used to compare specific pairs of exercise routines.\n",
    "\n",
    "Scheffe's Method:\n",
    "\n",
    "Use Case: Scheffe's method is used when you need to control the familywise error rate for all possible contrasts. It's a more conservative approach that can handle a wide range of comparisons, making it suitable for complex experimental designs.\n",
    "\n",
    "Example: In a two-way ANOVA studying the effects of diet type and exercise intensity on weight loss, the interaction effect is significant. Scheffe's method is applied to compare different combinations of diet types and exercise intensities.\n",
    "\n",
    "Fisher's Least Significant Difference (LSD):\n",
    "\n",
    "Use Case: Fisher's LSD is a less conservative post-hoc test that can be used when you have a specific hypothesis about which groups might differ. However, it doesn't control the familywise error rate as rigorously as some other methods.\n",
    "\n",
    "Example: In a study comparing the performance of three computer models for predicting stock prices, the ANOVA suggests differences among the models. Fisher's LSD is used to compare pairs of models that the researcher hypothesizes might be different.\n",
    "In summary, the choice of post-hoc test depends on factors like the number of groups, assumptions of the data, desired level of control over familywise error rate, and the nature of comparisons you need to make. The selected test should align with your research question and experimental design."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2133820d-f4ce-4eca-8953-fc9a8e4149f1",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b939ae5-aa9d-4e20-be5c-709f52c5d4cd",
   "metadata": {},
   "source": [
    "To conduct a one-way ANOVA using Python, you can use the scipy.stats module. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fcc100-1bd2-41d5-8557-4a76885cb22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 939.4800324772997\n",
      "p-value: 1.8216057628380463e-84\n",
      "There are significant differences between the mean weight loss of the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated weight loss data for three diets: A, B, and C\n",
    "diet_a = np.array([2.5, 3.2, 2.8, 2.1, 3.0, 2.7, 2.9, 3.4, 2.6, 2.3,\n",
    "                   2.4, 3.1, 2.9, 2.7, 2.8, 2.5, 3.3, 2.7, 2.9, 2.6,\n",
    "                   2.7, 3.0, 2.8, 2.9, 2.5, 3.2, 2.6, 2.8, 2.9, 3.1,\n",
    "                   2.4, 2.7, 2.5, 2.8, 2.6, 2.9, 2.7, 3.0, 2.8, 2.5,\n",
    "                   2.3, 3.2, 2.6, 2.7, 2.9, 3.1, 2.8, 2.5, 2.7, 2.9])\n",
    "\n",
    "diet_b = np.array([3.7, 3.8, 3.5, 3.2, 3.6, 3.9, 3.4, 3.3, 3.7, 3.5,\n",
    "                   3.6, 3.8, 3.4, 3.5, 3.7, 3.2, 3.9, 3.5, 3.4, 3.6,\n",
    "                   3.7, 3.8, 3.6, 3.5, 3.2, 3.7, 3.9, 3.4, 3.3, 3.5,\n",
    "                   3.6, 3.8, 3.4, 3.5, 3.7, 3.2, 3.9, 3.5, 3.4, 3.6,\n",
    "                   3.7, 3.8, 3.6, 3.5, 3.2, 3.7, 3.9, 3.4, 3.3, 3.5])\n",
    "\n",
    "diet_c = np.array([1.9, 1.8, 1.5, 2.0, 1.7, 1.6, 1.8, 1.9, 1.7, 1.6,\n",
    "                   1.5, 1.9, 1.8, 1.6, 1.7, 1.9, 1.5, 1.8, 1.6, 1.7,\n",
    "                   1.9, 1.8, 1.7, 1.5, 1.6, 1.9, 1.7, 1.8, 1.6, 1.7,\n",
    "                   1.9, 1.8, 1.6, 1.7, 1.5, 1.9, 1.7, 1.8, 1.6, 1.7,\n",
    "                   1.9, 1.8, 1.7, 1.5, 1.6, 1.9, 1.7, 1.8, 1.6, 1.7])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There are significant differences between the mean weight loss of the diets.\")\n",
    "else:\n",
    "    print(\"There are no significant differences between the mean weight loss of the diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9de2d-2684-48f8-9a0d-9230de9d21fb",
   "metadata": {},
   "source": [
    "In this example, I've used simulated weight loss data for three diets (A, B, and C). The f_oneway function from the scipy.stats module is used to perform the one-way ANOVA. The calculated F-statistic and p-value are printed, and based on the p-value, you can interpret the results.\n",
    "\n",
    "If the p-value is below your chosen significance level (e.g., 0.05), you can conclude that there are significant differences between the mean weight loss of the diets. If the p-value is not below the significance level, you would conclude that there are no significant differences between the mean weight loss of the diets."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d69f740-427b-4043-8f3b-9960a6647b73",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a40c-b624-4922-8175-3644a4e5a157",
   "metadata": {},
   "source": [
    "To conduct a two-way ANOVA using Python, you can use libraries like numpy, pandas, and statsmodels. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b52454-9e41-4689-b71d-2dead3311a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       df      sum_sq    mean_sq         F    PR(>F)\n",
      "Software              2.0    3.351449   1.675724  0.216246  0.805984\n",
      "Experience            1.0   11.466686  11.466686  1.479736  0.227223\n",
      "Software:Experience   2.0   18.892687   9.446343  1.219018  0.300694\n",
      "Residual             84.0  650.927849   7.749141       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Simulated data for the example\n",
    "np.random.seed(42)\n",
    "\n",
    "software = np.random.choice(['A', 'B', 'C'], size=90)\n",
    "experience = np.random.choice(['Novice', 'Experienced'], size=90)\n",
    "time_taken = np.random.normal(loc=15, scale=3, size=90)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Software': software, 'Experience': experience, 'TimeTaken': time_taken})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'TimeTaken ~ Software + Experience + Software:Experience'\n",
    "model = ols(formula, data).fit()\n",
    "anova_table = anova_lm(model)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f4153-8e9f-4cc4-871c-e27fefe665bb",
   "metadata": {},
   "source": [
    "In this example, the simulated data includes the software used, employee experience level, and the time taken to complete the task for each employee. The ols function from statsmodels is used to fit the two-way ANOVA model, and the anova_lm function is used to obtain the ANOVA table.\n",
    "\n",
    "The ANOVA table will include F-statistics and p-values for the main effects of the software, the main effects of experience, and the interaction effect between software and experience. Interpreting the results involves looking at the p-values:\n",
    "\n",
    "If the p-value for the main effect of software is below your chosen significance level (e.g., 0.05), you can conclude that there is a significant main effect of software on the time taken to complete the task.\n",
    "\n",
    "If the p-value for the main effect of experience is below your significance level, you can conclude that there is a significant main effect of experience on the time taken.\n",
    "\n",
    "If the p-value for the interaction effect between software and experience is below your significance level, you can conclude that there is a significant interaction effect, which implies that the effect of one factor depends on the level of the other factor."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7c04b4d-0a3e-43e5-9e6a-e22963f5f467",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5cd6c-fcde-4fbc-b231-b3c27c25b28e",
   "metadata": {},
   "source": [
    "To conduct a two-sample t-test and follow up with a post-hoc test, you can use libraries like numpy, scipy, and statsmodels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3993d95-2d52-4402-ac95-0881cea7c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test:\n",
      "t-statistic: -4.754695943505281\n",
      "p-value: 3.819135262679478e-06\n",
      "\n",
      "Tukey's HSD post-hoc test:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   6.2615   0.0 3.6645 8.8585   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Simulated test scores for the example\n",
    "np.random.seed(42)\n",
    "\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print(\"Two-sample t-test:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "data = np.concatenate([control_scores, experimental_scores])\n",
    "groups = np.array(['Control'] * 100 + ['Experimental'] * 100)\n",
    "tukey_results = mc.MultiComparison(data, groups).tukeyhsd()\n",
    "\n",
    "print(\"\\nTukey's HSD post-hoc test:\")\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24ea382b-6d65-4f2f-8e4c-23420f1e726a",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8a618-8e32-4a2c-9eea-f491699e4eac",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, the design typically involves measuring the same subjects or items under different conditions or at multiple time points. In your scenario, you are dealing with independent groups (stores) rather than repeated measures. For independent groups, a one-way ANOVA would be more appropriate.\n",
    "\n",
    "Here's how you can conduct a one-way ANOVA and follow up with a post-hoc test using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5900990-d5c1-40f5-9aff-2df07e962184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA:\n",
      "F-statistic: 9.96977591248324\n",
      "p-value: 0.00012634813711783394\n",
      "\n",
      "Tukey's HSD post-hoc test:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1  group2 meandiff p-adj   lower    upper   reject\n",
      "--------------------------------------------------------\n",
      "Store A Store B 110.9736 0.1051 -17.7004 239.6477  False\n",
      "Store A Store C 240.7217 0.0001 112.0477 369.3958   True\n",
      "Store B Store C 129.7481 0.0477    1.074 258.4222   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Simulated daily sales data for the example\n",
    "np.random.seed(42)\n",
    "\n",
    "store_a_sales = np.random.normal(loc=1000, scale=200, size=30)\n",
    "store_b_sales = np.random.normal(loc=1100, scale=220, size=30)\n",
    "store_c_sales = np.random.normal(loc=1200, scale=240, size=30)\n",
    "\n",
    "# Combine all sales data into one array\n",
    "all_sales = np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "\n",
    "# Create a grouping variable\n",
    "groups = np.array(['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "\n",
    "print(\"One-way ANOVA:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "tukey_results = mc.MultiComparison(all_sales, groups).tukeyhsd()\n",
    "\n",
    "print(\"\\nTukey's HSD post-hoc test:\")\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02390a3-17a9-46d0-9936-791169b656f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
